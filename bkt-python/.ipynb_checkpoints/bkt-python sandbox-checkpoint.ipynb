{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python implementation of Bayesian Knowledge Tracing (BKT)\n",
    "\n",
    "Benjamin Xie\n",
    "University of Washington\n",
    "bxie@uw.edu\n",
    "\n",
    "For Codeitz study\n",
    "\n",
    "Modifications to BKT:\n",
    "* KT-IDEM: Made guess and slip parameters part of item (not just part of skill/concept) so items are not homogenous (have \"difficulty\"). From Pardos & Heffernan 2011.\n",
    "* Sequencing algorithm: Using algorithm to select items. From David, Avi, & Ya'Akov 2016.\n",
    "\n",
    "## Terminology\n",
    "* item/exercise: unit representing a task which user does and gets scored. Each item maps to exactly _one_ concept. Each item has 2 parameters: slip and guess probabilities.\n",
    "* user: learner using Codeitz. A user attempts 0, 1, or many items. They have response data and probability of knowing a certain concept associated with them.\n",
    "* concept/skill: unit representing latent construct that user could learn. one or many items map to a concept. Each concept has 2 parameters: inital learning and transfer probabilities.\n",
    "\n",
    "## Notes\n",
    "* Code documentation roughly follow [NumPy style](https://sphinxcontrib-napoleon.readthedocs.io/en/latest/example_numpy.html)\n",
    "\n",
    "## References\n",
    "* David, Yossi Ben, Avi Segal, and Ya’akov (kobi) Gal. 2016. “Sequencing Educational Content in Classrooms Using Bayesian Knowledge Tracing.” In Proceedings of the Sixth International Conference on Learning Analytics & Knowledge, 354–63. ACM.\n",
    "* Pardos, Zachary A., and Neil T. Heffernan. 2011. “KT-IDEM: Introducing Item Difficulty to the Knowledge Tracing Model.” In User Modeling, Adaption and Personalization, 243–54. Springer Berlin Heidelberg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "INIT = 'init'\n",
    "TRANSFER = 'transfer'\n",
    "SLIP = 'slip'\n",
    "GUESS = 'guess'\n",
    "\n",
    "# concepts/skills\n",
    "VAR = 'variable'\n",
    "CONDITIONAL = 'conditional'\n",
    "CONCEPTS_LIST = [VAR, CONDITIONAL]\n",
    "ADJ_MATRIX = [\n",
    "    [1,1],\n",
    "    [0,1]\n",
    "]\n",
    "\n",
    "CONCEPT_MAP = {\n",
    "    \"concepts\": CONCEPTS_LIST,\n",
    "    \"adjMat\": ADJ_MATRIX\n",
    "              }\n",
    "\n",
    "# terms\n",
    "CONCEPT = 'concept'\n",
    "CONCEPTS_STR = 'concepts'\n",
    "ADJ_MAT_STR = \"adjMat\"\n",
    "EID = \"eid\"\n",
    "UID = 'uid'\n",
    "STEP = 'step'\n",
    "CORRECT = 'correct'\n",
    "IS_READ = 'is_read'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_concepts\n",
      "       concept  is_read  init  transfer\n",
      "0  conditional     True  0.10      0.30\n",
      "1  conditional    False  0.05      0.20\n",
      "2     variable     True  0.30      0.20\n",
      "3     variable    False  0.20      0.25\n",
      "\n",
      "df_items\n",
      "               eid  slip  guess      concept  is_read\n",
      "0          if/else  0.20   0.05  conditional     True\n",
      "1        read vars  0.05   0.20     variable     True\n",
      "2       write vars  0.10   0.10     variable    False\n",
      "3   more read vars  0.20   0.10     variable     True\n",
      "4  read var unused  0.15   0.11     variable     True\n",
      "\n",
      "df_learn\n",
      "Empty DataFrame\n",
      "Columns: [uid, concept, step, known]\n",
      "Index: []\n",
      "\n",
      "df_opp\n",
      "    uid             eid  step  correct\n",
      "0  alex       read vars     1        0\n",
      "1   sam       read vars     1        0\n",
      "2   sam      write vars     1        0\n",
      "3   sam  more read vars     2        1\n"
     ]
    }
   ],
   "source": [
    "# making example concepts\n",
    "c_init = pd.Series([0.1, 0.05, 0.3, 0.2])\n",
    "c_transfer = pd.Series([0.3, 0.2, 0.2, 0.25])\n",
    "c_concepts = pd.Series([CONDITIONAL, CONDITIONAL, VAR, VAR])\n",
    "c_read = pd.Series([True, False, True, False])\n",
    "\n",
    "df_concepts = pd.DataFrame({CONCEPT: c_concepts, IS_READ: c_read, INIT:c_init, TRANSFER:c_transfer})\n",
    "print('df_concepts')\n",
    "print(df_concepts)\n",
    "\n",
    "# making example item (exercise)\n",
    "ex_ids = pd.Series(['if/else', 'read vars', 'write vars', 'more read vars', 'read var unused'])\n",
    "ex_slips = pd.Series([0.2, 0.05, 0.1, 0.2, 0.15])\n",
    "ex_guesses = pd.Series([0.05, 0.2, 0.1, 0.1, 0.11])\n",
    "ex_concepts = pd.Series([CONDITIONAL, VAR, VAR, VAR, VAR])\n",
    "ex_is_read = pd.Series([True, True, False, True, True])\n",
    "\n",
    "# item 0 should be harder, 1 should be easier, 2 in the middle\n",
    "df_items = pd.DataFrame({EID: ex_ids, SLIP:ex_slips, GUESS:ex_guesses, CONCEPT:ex_concepts, IS_READ: ex_is_read})\n",
    "print('\\ndf_items')\n",
    "print(df_items)\n",
    "\n",
    "# making ledger of \n",
    "k_ids = pd.Series(['alex', 'sam'])\n",
    "df_learn = pd.DataFrame(columns=['uid', 'concept', 'step', 'known'])\n",
    "print('\\ndf_learn')\n",
    "print(df_learn)\n",
    "\n",
    "# making example responses\n",
    "opp_uids = pd.Series(['alex', 'sam', 'sam', 'sam'])\n",
    "opp_eids = pd.Series(['read vars', 'read vars', 'write vars', 'more read vars'])\n",
    "opp_step = pd.Series([1, 1, 1, 2])\n",
    "opp_correct = pd.Series([0, 0, 0, 1])\n",
    "\n",
    "df_opp = pd.DataFrame({'uid':opp_uids, 'eid': opp_eids, 'step': opp_step, 'correct': opp_correct})\n",
    "print('\\ndf_opp')\n",
    "print(df_opp) # TODO: add timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>concept</th>\n",
       "      <th>step</th>\n",
       "      <th>known</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [uid, concept, step, known]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concepts\n",
    "df_items\n",
    "df_opp\n",
    "df_learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BKT functions w/ item difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# done! (but not fully tested)\n",
    "def posterior_pknown(is_correct, eid, transfer, item_params, prior_pknown):\n",
    "    \"\"\"\n",
    "    updates BKT estimate of learner knowledge\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    is_correct: boolean\n",
    "        True if response was correct\n",
    "    eid: String\n",
    "        exercise ID\n",
    "    transfer: float\n",
    "        transfer probability for concept\n",
    "    item_params: pd.DataFrame\n",
    "        slip and guess parameters for each item\n",
    "    prior_pknown: float\n",
    "        prior probability user learned this concept (read, write are different concepts)\n",
    "    \"\"\"\n",
    "    if not eid in item_params[EID].unique():\n",
    "        raise Exception('Given exercise ID not in response data. Return w/ no update. EID is {}'.format(eid))\n",
    "        return prior_pknown\n",
    "\n",
    "    posterior = -1.0\n",
    "    slip = float(item_params[item_params[EID] == eid][SLIP])\n",
    "    guess = float(item_params[item_params[EID] == eid][GUESS])\n",
    "    \n",
    "    if is_correct:\n",
    "        posterior = (prior_pknown * (1.0 - slip)) / ((prior_pknown * (1 - slip)) + ((1.0-prior_pknown)*guess))\n",
    "    else:\n",
    "        posterior = (prior_pknown * slip) / ((prior_pknown * slip) + ((1.0-prior_pknown)*(1.0-guess)))\n",
    "    \n",
    "    return (posterior + (1.0-posterior) * transfer)\n",
    "\n",
    "\n",
    "def pknown_seq(uid, concept, df_opp, concept_params, item_params, is_read=True):\n",
    "    \"\"\"\n",
    "    Predict sequence of probability a concept is known after each step.\n",
    "    Function not used in real-time, but may be used to batch update pknown (e.g. if concept or exercise params updated)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    uid: String\n",
    "        learner/user ID\n",
    "    concept: String\n",
    "        concept name\n",
    "    df_opp: pd.DataFrame\n",
    "        dataframe which records the correctness of responses for users. columns: uid, eid, step, correct\n",
    "    concept_params: pd.DataFrame\n",
    "        concept parameters (concept, init, transfer)\n",
    "    item_params: pd.DataFrame\n",
    "        item parameters (eid, slip, guess, concept)\n",
    "    is_read: Boolean\n",
    "        True if concept relates to reading, False if it relates to writing\n",
    "    \"\"\"\n",
    "    \n",
    "    eids = item_params[(item_params[CONCEPT] == concept) & (item_params[IS_READ] == is_read)][EID]\n",
    "    \n",
    "    # grab exercise sequence for specific user working on specific concept\n",
    "    exercise_seq = df_opp[(df_opp[UID] == uid) & (df_opp[EID].isin(eids))]\n",
    "    \n",
    "    n_opps = len(exercise_seq) # number exercises attempted\n",
    "    \n",
    "    # filtering for 1 concept to update\n",
    "    concept_params_target = concept_params[(concept_params[CONCEPT] == concept) & (concept_params[IS_READ] == is_read)]\n",
    "    \n",
    "    pk = pd.Series(np.zeros(n_opps + 1))    \n",
    "    pk[0] = float(concept_params_target[INIT])\n",
    "    \n",
    "    if(n_opps > 0):\n",
    "        transfer = float(concept_params_target[TRANSFER])        \n",
    "        \n",
    "        for step in range(1,n_opps+1):\n",
    "            df_step = exercise_seq[exercise_seq[STEP]==step]\n",
    "            if(len(df_step) != 1):\n",
    "                raise Exception('Did not find exactly 1 response for user {} for step {}. Found {}'\n",
    "                                .format(uid, step, len(df_step)))\n",
    "\n",
    "            is_correct = df_step.iloc[0][CORRECT]\n",
    "            eid = df_step.iloc[0][EID]\n",
    "            \n",
    "            pk[step] = posterior_pknown(is_correct, eid, transfer, item_params, pk[step - 1])\n",
    "    return pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# done! (lightly tested)\n",
    "def pcorrect(pk, slip, guess):\n",
    "    return (pk * (1.0-slip)) + ((1.0 - pk) * guess)\n",
    "    \n",
    "def pcorrect_seq(uid, concept, df_opp, concept_params, item_params, is_read=True):\n",
    "    \"\"\"\n",
    "    Probability of correct responses predicted by BKT.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    uid: String\n",
    "        learner/user ID\n",
    "    concept: String\n",
    "        concept name\n",
    "    df_opp: pd.DataFrame\n",
    "        dataframe which records the correctness of responses for users. columns: uid, eid, step, correct\n",
    "    concept_params: pd.DataFrame\n",
    "        concept parameters (concept, init, transfer)\n",
    "    item_params: pd.DataFrame\n",
    "        item parameters (eid, slip, guess, concept)\n",
    "    is_read: Boolean\n",
    "        True if concept relates to reading, False if it relates to writing    \n",
    "    \"\"\"\n",
    "    eids = item_params[item_params[CONCEPT] == concept][EID]\n",
    "    \n",
    "    # grab exercise sequence for specific user working on specific concept\n",
    "    exercise_seq = df_opp[(df_opp[UID] == uid) & (df_opp[EID].isin(eids))]    \n",
    "    n_opps = len(exercise_seq) # number exercises attempted\n",
    "\n",
    "    pk = pknown_seq(uid, concept, df_opp, concept_params, item_params, is_read)\n",
    "    pc = pd.Series(np.zeros(n_opps))\n",
    "    for step in range(0,len(pc)):\n",
    "        eid = exercise_seq.iloc[step][EID]\n",
    "        slip = float(item_params[item_params[EID] == eid][SLIP])\n",
    "        guess = float(item_params[item_params[EID] == eid][GUESS])\n",
    "        pc[step] = pcorrect(pk[step], slip, guess)\n",
    "\n",
    "    return pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_next_questions(exercise_ids, pk, item_params, error = 0.0, penalty = 1.0):\n",
    "    \"\"\"\n",
    "    Order questions based on \"most answerable.\" \n",
    "    Exercise IDs and probability of known must be of same concept, either read or write.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    exercise_ids: list\n",
    "        list of exercise ids (Strings) for same concept\n",
    "    pk: float\n",
    "        probability concept is known\n",
    "    item_params: pd.DataFrame\n",
    "        item parameters (eid, slip, guess, concept)\n",
    "    \"\"\"\n",
    "    \n",
    "    df_output = pd.DataFrame({\"eid\": exercise_ids, \"score\": np.zeros(len(exercise_ids))})\n",
    "    \n",
    "    # get max and min scores/p(correct)\n",
    "    for eid in exercise_ids:\n",
    "        params = item_params[item_params[EID] == eid].iloc[0]\n",
    "        df_output.loc[df_output[EID] == eid, 'score'] = pcorrect(pk, params[SLIP], params[GUESS])\n",
    "\n",
    "    min_score = min(df_output['score'])\n",
    "    max_score = max(df_output['score'])\n",
    "    target_score = min_score + ((max_score - min_score) * (1 - pk + error))\n",
    "#     print('target_score: {}'.format(target_score))\n",
    "    \n",
    "    df_output['diff'] = abs(df_output['score'] - target_score) * penalty\n",
    "    \n",
    "#     print(df_output)\n",
    "    return df_output.sort_values(by='diff')[EID]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eid</th>\n",
       "      <th>score</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>read vars</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>write vars</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>more read vars</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>read var unused</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>if/else</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               eid  score  diff\n",
       "1        read vars    0.0   1.0\n",
       "2       write vars    0.0   1.0\n",
       "3   more read vars    0.0   1.0\n",
       "4  read var unused    0.0   1.0\n",
       "0          if/else    0.5   1.5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eids = df_items[EID].unique()\n",
    "df_output = pd.DataFrame({\"eid\": eids, \"score\": np.zeros(len(eids))})\n",
    "df_output.loc[df_output['eid']=='if/else', 'score'] = 0.5\n",
    "df_output['diff'] = df_output['score'] + 1\n",
    "df_output.sort_values(by='score')\n",
    "# df.ix[df['id'] == 12, ['uid','gid']] = ['IN','IN-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_pknown(is_correct, eid, transfer, item_params, prior_pknown):\n",
    "    \"\"\"\n",
    "    updates BKT estimate of learner knowledge\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    result: boolean\n",
    "        True if response was correct\n",
    "    eid: String\n",
    "        exercise ID\n",
    "    transfer: float\n",
    "        transfer probability for concept\n",
    "    item_params: pd.DataFrame\n",
    "        slip and guess parameters for each item\n",
    "    prior_pknown: float\n",
    "        prior probability user learned this concept (read, write are different concepts)\n",
    "    \"\"\"\n",
    "    if not eid in item_params[EID].unique():\n",
    "        raise Exception(\n",
    "            'Given exercise ID not in response data. Return w/ no update. EID is {}'.format(eid))\n",
    "        return prior_pknown\n",
    "\n",
    "    posterior = -1.0\n",
    "    slip = float(item_params[item_params[EID] == eid][SLIP])\n",
    "    guess = float(item_params[item_params[EID] == eid][GUESS])\n",
    "\n",
    "    if is_correct:\n",
    "        posterior = (prior_pknown * (1.0 - slip)) / ((prior_pknown * (1 - slip)) + ((1.0-prior_pknown)*guess))\n",
    "    else:\n",
    "        posterior = (prior_pknown * slip) / ((prior_pknown * slip) + ((1.0-prior_pknown)*(1.0-guess)))\n",
    "    \n",
    "    return (posterior + (1.0-posterior) * transfer)\n",
    "\n",
    "\n",
    "def pknown_seq(uid, concept, df_opp, concept_params, item_params, is_read=True):\n",
    "    \"\"\"\n",
    "    Predict sequence of probability a concept is known after each step.\n",
    "    Function not used in real-time, but may be used to batch update pknown (e.g. if concept or exercise params updated)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    uid: String\n",
    "        learner/user ID\n",
    "    concept: String\n",
    "        concept name\n",
    "    df_opp: pd.DataFrame\n",
    "        dataframe which records the correctness of responses for users. columns: uid, eid, step, correct\n",
    "    concept_params: pd.DataFrame\n",
    "        concept parameters (concept, init, transfer)\n",
    "    item_params: pd.DataFrame\n",
    "        item parameters (eid, slip, guess, concept)\n",
    "    is_read: Boolean\n",
    "        True if concept relates to reading, False if it relates to writing\n",
    "    \"\"\"\n",
    "    \n",
    "    eids = item_params[(item_params[CONCEPT] == concept) & (item_params[IS_READ] == is_read)][EID]\n",
    "    \n",
    "    # grab exercise sequence for specific user working on specific concept\n",
    "    exercise_seq = df_opp[(df_opp[UID] == uid) & (df_opp[EID].isin(eids))]\n",
    "    \n",
    "    n_opps = len(exercise_seq) # number exercises attempted\n",
    "    \n",
    "    # filtering for 1 concept to update\n",
    "    concept_params_target = concept_params[(concept_params[CONCEPT] == concept) & (concept_params[IS_READ] == is_read)]\n",
    "    \n",
    "    pk = pd.Series(np.zeros(n_opps + 1))    \n",
    "    pk[0] = float(concept_params_target[INIT])\n",
    "    \n",
    "    if(n_opps > 0):\n",
    "        transfer = float(concept_params_target[TRANSFER])        \n",
    "        \n",
    "        for step in range(1,n_opps+1):\n",
    "            df_step = exercise_seq[exercise_seq[STEP]==step]\n",
    "            if(len(df_step) != 1):\n",
    "                raise Exception('Did not find exactly 1 response for user {} for step {}. Found {}'\n",
    "                                .format(uid, step, len(df_step)))\n",
    "\n",
    "            is_correct = df_step.iloc[0][CORRECT]\n",
    "            eid = df_step.iloc[0][EID]\n",
    "            \n",
    "            pk[step] = posterior_pknown(is_correct, eid, transfer, item_params, pk[step - 1])\n",
    "    return pk\n",
    "\n",
    "\n",
    "def pcorrect(pk, slip, guess):\n",
    "    return (pk * (1.0-slip)) + ((1.0 - pk) * guess)\n",
    "\n",
    "\n",
    "def pcorrect_seq(uid, concept, df_opp, concept_params, item_params, is_read=True):\n",
    "    \"\"\"\n",
    "    Probability of correct responses predicted by BKT.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    uid: String\n",
    "        learner/user ID\n",
    "    concept: String\n",
    "        concept name\n",
    "    df_opp: pd.DataFrame\n",
    "        dataframe which records the correctness of responses for users. columns: uid, eid, step, correct\n",
    "    concept_params: pd.DataFrame\n",
    "        concept parameters (concept, init, transfer)\n",
    "    item_params: pd.DataFrame\n",
    "        item parameters (eid, slip, guess, concept)\n",
    "    is_read: Boolean\n",
    "        True if concept relates to reading, False if it relates to writing    \n",
    "    \"\"\"\n",
    "    eids = item_params[item_params[CONCEPT] == concept][EID]\n",
    "    \n",
    "    # grab exercise sequence for specific user working on specific concept\n",
    "    exercise_seq = df_opp[(df_opp[UID] == uid) & (df_opp[EID].isin(eids))]    \n",
    "    n_opps = len(exercise_seq) # number exercises attempted\n",
    "\n",
    "    pk = pknown_seq(uid, concept, df_opp, concept_params, item_params, is_read)\n",
    "    pc = pd.Series(np.zeros(n_opps))\n",
    "    for step in range(0,len(pc)):\n",
    "        eid = exercise_seq.iloc[step][EID]\n",
    "        slip = float(item_params[item_params[EID] == eid][SLIP])\n",
    "        guess = float(item_params[item_params[EID] == eid][GUESS])\n",
    "        pc[step] = pcorrect(pk[step], slip, guess)\n",
    "\n",
    "    return pc\n",
    "\n",
    "\n",
    "def order_next_questions(exercise_ids, pk, item_params, error = 0.0, penalty = 1.0):\n",
    "    \"\"\"\n",
    "    Order questions based on \"most answerable.\" \n",
    "    Exercise IDs and probability of known must be of same concept, either read or write.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    exercise_ids: list\n",
    "        list of exercise ids, potentially from multiple concepts (Strings)\n",
    "    pk: float\n",
    "        probability concept is known\n",
    "    item_params: pd.DataFrame\n",
    "        item parameters (eid, slip, guess, concept)\n",
    "    \"\"\"\n",
    "    df_output = pd.DataFrame({\"eid\": exercise_ids, \"score\": np.zeros(len(exercise_ids))})\n",
    "    df_item_params = pd.DataFrame.from_dict(item_params)\n",
    "    \n",
    "    # get max and min scores/p(correct)\n",
    "    for eid in exercise_ids:\n",
    "        if eid in list(df_item_params):\n",
    "            params = df_item_params[df_item_params[EID] == eid].iloc[0]\n",
    "            df_output.loc[df_output[EID] == eid, 'score'] = pcorrect(pk, params[SLIP], params[GUESS])\n",
    "\n",
    "    min_score = min(df_output['score'])\n",
    "    max_score = max(df_output['score'])\n",
    "    target_score = min_score + ((max_score - min_score) * (1 - pk + error))\n",
    "    \n",
    "    df_output['diff'] = abs(df_output['score'] - target_score) * penalty\n",
    "    \n",
    "    return list(df_output.sort_values(by='diff')[EID])\n",
    "\n",
    "def filter_ordered_questions_by_concepts(questions, item_params, target_concept, concept_map, \n",
    "                                         max_num_target=3, max_num_child=1, max_num_parent=1):\n",
    "    \"\"\"\n",
    "    Given ordered concept, filter recommendations such that there are at most the max number \n",
    "    for a target concept and parent & child concepts\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    questions: list\n",
    "        ordered list of exercise ids (strings) where index 0 is 1st (most recommended) exercise\n",
    "    item_params: pd.DataFrame\n",
    "        item parameters (eid, slip, guess, concept)\n",
    "    target_concept: string\n",
    "        \n",
    "    concept_map: dict\n",
    "        dictionary with 2 attributes: {concepts, adjMat}. \n",
    "        adjMat is a list of lists which serves as an adjacency matrix for the concept map (directed graph)\n",
    "        concepts is a list of concepts where a concept at index i maps to the same index on adjMat\n",
    "    max_num_target: int\n",
    "        maximum number of recommendations for a target concept. Must be >=0\n",
    "    max_num_child: int\n",
    "        maximum number of recommendations for a child of the target concept. Must be >= 0\n",
    "    max_num_parent: int\n",
    "        maximum number of recommendations for a parent of the target concept. Must be >=0\n",
    "    \"\"\"\n",
    "    \n",
    "    output = []\n",
    "    \n",
    "    def get_parents(target, concept_map):\n",
    "        \"\"\"\n",
    "        Given a target concept, return a list of concept IDs for parent concepts\n",
    "        \"\"\"\n",
    "        parents = []\n",
    "        target_index = concept_map[CONCEPTS_STR].index(target)\n",
    "        for row in range(len(concept_map[ADJ_MAT_STR])): \n",
    "            val = concept_map[ADJ_MAT_STR][row][target_index] # get value in adjMat for each row at target concept's col\n",
    "            if val > 0 and target_index != row: # don't care concepts are their own parents\n",
    "                parents.append(concept_map[CONCEPTS_STR][row])\n",
    "        return parents\n",
    "\n",
    "    def get_children(target, concept_map):\n",
    "        \"\"\"\n",
    "        Given a target concept, return a list of concept IDs for all child concepts\n",
    "        \"\"\"\n",
    "        child_inds = []\n",
    "        target_index = concept_map[CONCEPTS_STR].index(target)\n",
    "        target_row = concept_map[ADJ_MAT_STR][target_index]\n",
    "        for ind in range(len(target_row)): # for each ind in row of adj mat\n",
    "            val = target_row[ind]\n",
    "            if(val>0 and ind != target_index): # don't care concept is child of itself\n",
    "                child_inds.append(ind)\n",
    "        return list(map(lambda ind: concept_map[CONCEPTS_STR][ind], child_inds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = 0\n",
    "eid = 'read vars'\n",
    "transfer = df_concepts[df_concepts[CONCEPT]==VAR][TRANSFER]\n",
    "item_params = df_items\n",
    "prior_pknown = df_concepts[df_concepts[CONCEPT]==VAR][INIT]\n",
    "\n",
    "correct= result==1\n",
    "posterior = pd.Series(np.zeros(1))\n",
    "slip = item_params[item_params[EID] == eid][SLIP]\n",
    "guess = item_params[item_params[EID] == eid][GUESS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_params[item_params[EID] == 'read vars'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing pknown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posterior_pknown(is_correct, eid, transfer, item_params, prior_pknown)\n",
    "new_prior = posterior_pknown(0, 'read vars',df_concepts[(df_concepts[CONCEPT]==VAR) & df_concepts[IS_READ]][TRANSFER], df_items, df_concepts[(df_concepts[CONCEPT]==VAR) & df_concepts[IS_READ]][INIT])\n",
    "\n",
    "print(new_prior)\n",
    "# new_prior_2 = posterior_pknown(0, 'read vars', df_concepts[df_concepts[CONCEPT]==VAR][TRANSFER], df_items, new_prior)\n",
    "# print(new_prior_2)\n",
    "# print(posterior_pknown(0, 'read vars', df_concepts[df_concepts[CONCEPT]==VAR][TRANSFER], df_items, new_prior_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing pknown_seq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid = 'sam'\n",
    "concept = 'variable'\n",
    "item_params = df_items\n",
    "concept_params = df_concepts\n",
    "is_read = True\n",
    "pknown_seq(uid, concept, df_opp, concept_params, item_params, is_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing pcorrect_seq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pcorrect_seq(uid, concept, df_opp, concept_params, item_params, is_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eids = item_params[item_params[CONCEPT] == concept][EID]\n",
    "    \n",
    "# grab exercise sequence for specific user working on specific concept\n",
    "exercise_seq = df_opp[(df_opp[UID] == uid) & (df_opp[EID].isin(eids))]    \n",
    "n_opps = len(exercise_seq) # number exercises attempted\n",
    "\n",
    "pk = pknown_seq(uid, concept, df_opp, concept_params, item_params)\n",
    "pc = pd.Series(np.zeros(n_opps))\n",
    "for step in range(0,len(pc)):\n",
    "    eid = exercise_seq.iloc[step][EID]\n",
    "    slip = float(item_params[item_params[EID] == eid][SLIP])\n",
    "    guess = float(item_params[item_params[EID] == eid][GUESS])\n",
    "    pc[step] = (pk[step] * (1.0-slip)) + ((1.0-pk[step]) * guess)\n",
    "pc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing order_next_question()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1], [0, 1]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concept = 'variable'\n",
    "# exercise_ids = df_items[(df_items[CONCEPT] == concept) & (df_items[IS_READ] == True)][EID]\n",
    "exercise_ids = df_items[EID]\n",
    "pk = 0.51\n",
    "item_params = df_items\n",
    "concept_map = CONCEPT_MAP\n",
    "error = 0.0\n",
    "penalty = 1.0\n",
    "\n",
    "# tmp = order_next_questions(list(exercise_ids)+ ['FAKE'], pk, item_params)\n",
    "# type(tmp)\n",
    "# list(tmp)\n",
    "\n",
    "concept_map[\"concepts\"]\n",
    "concept_map[\"adjMat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items[df_items[CONCEPT] == concept]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = {\"itemParams\":[{\"guess\":0.05,\"slip\":0.15,\"eid\":\"-LH_KNtUIv-mnBkZz2-k\",\"concept\":\"dataTypes\"}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(exercise_ids):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_params\n",
    "# float(item_params[item_params[EID] == \"if/else\"][SLIP].iloc[0])\n",
    "float(item_params[item_params[GUESS] == 0.1][SLIP].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2         write vars\n",
      "4    read var unused\n",
      "3     more read vars\n",
      "0            if/else\n",
      "1          read vars\n",
      "Name: eid, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Order questions based on \"most answerable.\" \n",
    "Exercise IDs and probability of known must be of same concept, either read or write.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "exercise_ids: list\n",
    "    list of exercise ids (Strings)\n",
    "pk: float\n",
    "    probability concept is known\n",
    "item_params: pd.DataFrame\n",
    "    item parameters (eid, slip, guess, concept)\n",
    "\"\"\"\n",
    "\n",
    "df_output = pd.DataFrame({\"eid\": exercise_ids, \"score\": np.zeros(len(exercise_ids))})\n",
    "\n",
    "# get max and min scores/p(correct)\n",
    "for eid in exercise_ids:\n",
    "#     print(\"{} ?= {}\".format(item_params[EID], eid)) # TODO remove\n",
    "    if eid in list(item_params[EID]):\n",
    "        params = item_params[item_params[EID] == eid].iloc[0]\n",
    "        df_output.loc[df_output[EID] == eid, 'score'] = pcorrect(pk, params[SLIP], params[GUESS])\n",
    "\n",
    "min_score = min(df_output['score'])\n",
    "max_score = max(df_output['score'])\n",
    "target_score = min_score + ((max_score - min_score) * (1 - pk + error))\n",
    "\n",
    "df_output['diff'] = abs(df_output['score'] - target_score) * penalty\n",
    "\n",
    "print(df_output.sort_values(by='diff')[EID])\n",
    "# print(df_output.sort_values(by='diff'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"read vars\" in list(item_params[EID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(exercise_ids).index('write vars')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing filtering of ordered questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = CONDITIONAL\n",
    "parents = []\n",
    "\n",
    "child_inds = []\n",
    "target_index = concept_map[CONCEPTS_STR].index(target)\n",
    "target_row = concept_map[ADJ_MAT_STR][target_index]\n",
    "for ind in range(len(target_row)): # for each ind in row of adj mat\n",
    "    val = target_row[ind]\n",
    "    if(val>0 and ind != target_index): # don't care concept is child of itself\n",
    "        child_inds.append(ind)\n",
    "list(map(lambda ind: concept_map[CONCEPTS_STR][ind], child_inds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda val:val == 1, concept_map[ADJ_MAT_STR][target_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concept_map[ADJ_MAT_STR][target_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
